{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "\n",
      "device: \tcuda\t\n",
      "display_step: \t10\t\n",
      "res_dir: \t./results\t\n",
      "ex_name: \tdebug\t\n",
      "use_gpu: \tTrue\t\n",
      "gpu: \t0\t\n",
      "seed: \t111\t\n",
      "data_name: \tCATH\t\n",
      "data_root: \t./data/\t\n",
      "batch_size: \t8\t\n",
      "num_workers: \t8\t\n",
      "method: \tProDesign\t\n",
      "config_file: \tNone\t\n",
      "hidden_dim: \t128\t\n",
      "node_features: \t128\t\n",
      "edge_features: \t128\t\n",
      "k_neighbors: \t30\t\n",
      "dropout: \t0.1\t\n",
      "num_encoder_layers: \t10\t\n",
      "epoch: \t100\t\n",
      "log_step: \t1\t\n",
      "lr: \t0.001\t\n",
      "patience: \t100\t\n",
      "updating_edges: \t4\t\n",
      "node_dist: \t1\t\n",
      "node_angle: \t1\t\n",
      "node_direct: \t1\t\n",
      "edge_dist: \t1\t\n",
      "edge_angle: \t1\t\n",
      "edge_direct: \t1\t\n",
      "virtual_num: \t3\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "# Set-up parameters\n",
    "parser.add_argument('--device', default='cuda', type=str, help='Name of device to use for tensor computations (cuda/cpu)')\n",
    "parser.add_argument('--display_step', default=10, type=int, help='Interval in batches between display of training metrics')\n",
    "parser.add_argument('--res_dir', default='./results', type=str)\n",
    "parser.add_argument('--ex_name', default='debug', type=str)\n",
    "parser.add_argument('--use_gpu', default=True, type=bool)\n",
    "parser.add_argument('--gpu', default=0, type=int)\n",
    "parser.add_argument('--seed', default=111, type=int)\n",
    "\n",
    "# CATH\n",
    "# dataset parameters\n",
    "parser.add_argument('--data_name', default='CATH', choices=['CATH', 'TS50'])\n",
    "parser.add_argument('--data_root', default='./data/')\n",
    "parser.add_argument('--batch_size', default=8, type=int)\n",
    "parser.add_argument('--num_workers', default=8, type=int)\n",
    "\n",
    "# method parameters\n",
    "parser.add_argument('--method', default='ProDesign', choices=['ProDesign'])\n",
    "parser.add_argument('--config_file', '-c', default=None, type=str)\n",
    "parser.add_argument('--hidden_dim',  default=128, type=int)\n",
    "parser.add_argument('--node_features',  default=128, type=int)\n",
    "parser.add_argument('--edge_features',  default=128, type=int)\n",
    "parser.add_argument('--k_neighbors',  default=30, type=int)\n",
    "parser.add_argument('--dropout',  default=0.1, type=int)\n",
    "parser.add_argument('--num_encoder_layers', default=10, type=int)\n",
    "\n",
    "# Training parameters\n",
    "parser.add_argument('--epoch', default=100, type=int, help='end epoch')\n",
    "parser.add_argument('--log_step', default=1, type=int)\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='Learning rate')\n",
    "parser.add_argument('--patience', default=100, type=int)\n",
    "\n",
    "# ProDesign parameters\n",
    "parser.add_argument('--updating_edges', default=4, type=int)\n",
    "parser.add_argument('--node_dist', default=1, type=int)\n",
    "parser.add_argument('--node_angle', default=1, type=int)\n",
    "parser.add_argument('--node_direct', default=1, type=int)\n",
    "parser.add_argument('--edge_dist', default=1, type=int)\n",
    "parser.add_argument('--edge_angle', default=1, type=int)\n",
    "parser.add_argument('--edge_direct', default=1, type=int)\n",
    "parser.add_argument('--virtual_num', default=3, type=int)\n",
    "args = parser.parse_args([])\n",
    "\n",
    "import torch\n",
    "from main import Exp\n",
    "from parser import create_parser\n",
    "exp = Exp(args)\n",
    "svpath = './results/ProDesign/'\n",
    "exp.method.model.load_state_dict(torch.load(svpath+'checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Results on CATH4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.test()\n",
    "print(\"median: {:.4f}\\t mean: {:.4f}\\t std: {:.4f}\\t min: {:.4f}\\t max: {:.4f}\".format(exp.method.median_recovery, exp.method.mean_recovery, exp.method.std_recovery, exp.method.min_recovery, exp.method.max_recovery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results on TS50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from API.dataloader import make_cath_loader\n",
    "from API.cath_dataset import CATH\n",
    "\n",
    "with open('./data/ts/ts50.json','r') as f:\n",
    "    ts50 = json.load(f)\n",
    "\n",
    "\n",
    "ts50_list = []\n",
    "for entry in ts50:\n",
    "    coords = np.array(entry['coords'])\n",
    "    ts50_list.append(\n",
    "        {\n",
    "                    'title':entry['name'],\n",
    "                    'seq':entry['seq'],\n",
    "                    'CA':coords[:,1,:],\n",
    "                    'C':coords[:,2,:],\n",
    "                    'O':coords[:,3,:],\n",
    "                    'N':coords[:,0,:]\n",
    "        }\n",
    "    )\n",
    "exp.test_loader = make_cath_loader(CATH(data=ts50_list), 'SimDesign', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss: 1.2509: 100%|██████████| 7/7 [00:01<00:00,  5.54it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 29.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Perp: 3.8553, Test Rec: 0.5872\n",
      "\n",
      "Category Unknown Rec: 0.5872\n",
      "\n",
      "median: 0.5872\t mean: 0.5654\t std: 0.0887\t min: 0.3724\t max: 0.7530\n"
     ]
    }
   ],
   "source": [
    "exp.test()\n",
    "print(\"median: {:.4f}\\t mean: {:.4f}\\t std: {:.4f}\\t min: {:.4f}\\t max: {:.4f}\".format(exp.method.median_recovery, exp.method.mean_recovery, exp.method.std_recovery, exp.method.min_recovery, exp.method.max_recovery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on TS500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ts/ts500.json','r') as f:\n",
    "    ts500 = json.load(f)\n",
    "\n",
    "\n",
    "ts500_list = []\n",
    "for entry in ts500:\n",
    "    coords = np.array(entry['coords'])\n",
    "    ts500_list.append(\n",
    "        {\n",
    "                    'title':entry['name'],\n",
    "                    'seq':entry['seq'],\n",
    "                    'CA':coords[:,1,:],\n",
    "                    'C':coords[:,2,:],\n",
    "                    'O':coords[:,3,:],\n",
    "                    'N':coords[:,0,:]\n",
    "        }\n",
    "    )\n",
    "exp.test_loader = make_cath_loader(CATH(data=ts500_list), 'SimDesign', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss: 1.6132: 100%|██████████| 63/63 [00:06<00:00,  9.68it/s]\n",
      "100%|██████████| 500/500 [00:17<00:00, 28.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Perp: 3.4403, Test Rec: 0.6046\n",
      "\n",
      "Category Unknown Rec: 0.6046\n",
      "\n",
      "median: 0.6046\t mean: 0.5932\t std: 0.1077\t min: 0.0296\t max: 0.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exp.test()\n",
    "print(\"median: {:.4f}\\t mean: {:.4f}\\t std: {:.4f}\\t min: {:.4f}\\t max: {:.4f}\".format(exp.method.median_recovery, exp.method.mean_recovery, exp.method.std_recovery, exp.method.min_recovery, exp.method.max_recovery))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "AAMAP = {\n",
    "    'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C', 'GLN': 'Q',\n",
    "    'GLU': 'E', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I', 'LEU': 'L', 'LYS': 'K',\n",
    "    'MET': 'M', 'PHE': 'F', 'PRO': 'P', 'SER': 'S', 'THR': 'T', 'TRP': 'W',\n",
    "    'TYR': 'Y', 'VAL': 'V',\n",
    "    'ASX': 'B', 'GLX': 'Z', 'SEC': 'U', 'PYL': 'O', 'XLE': 'J', '': '-'\n",
    "}\n",
    "\n",
    "# def get_pdb(pdb_code=\"\"):\n",
    "#   if pdb_code is None or pdb_code == \"\":\n",
    "#     upload_dict = files.upload()\n",
    "#     pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
    "#     with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
    "#     return \"tmp.pdb\"\n",
    "#   else:\n",
    "#     os.system(f\"wget -qnc https://files.rcsb.org/view/{pdb_code}.pdb\")\n",
    "#     return f\"{pdb_code}.pdb\"\n",
    "\n",
    "def getSequence(resnames):\n",
    "    \"\"\"Returns polypeptide sequence as from list of *resnames* (residue\n",
    "    name abbreviations).\"\"\"\n",
    "\n",
    "    get = AAMAP.get\n",
    "    return ''.join([get(rn, 'X') for rn in resnames])\n",
    "\n",
    "def gzip_open(filename, *args, **kwargs):\n",
    "    if args and \"t\" in args[0]:\n",
    "        args = (args[0].replace(\"t\", \"\"), ) + args[1:]\n",
    "    if isinstance(filename, str):\n",
    "        return gzip.open(filename, *args, **kwargs)\n",
    "    else:\n",
    "        return gzip.GzipFile(filename, *args, **kwargs)\n",
    "\n",
    "def parsePDB(pdb, chain=['A']):\n",
    "    title, ext = os.path.splitext(os.path.split(pdb)[1])\n",
    "    title, ext = os.path.splitext(title)\n",
    "    pdb = gzip_open(pdb, 'rt')\n",
    "    \n",
    "    lines = defaultdict(list)\n",
    "    for loc, line in enumerate(pdb):\n",
    "        line = line.decode('ANSI_X3.4-1968')\n",
    "        startswith = line[0:6]\n",
    "        lines[startswith].append((loc, line))\n",
    "    pdb.close()\n",
    "    \n",
    "    sequence = ''\n",
    "    # for idx, line in lines['SEQRES']:\n",
    "    #     if line[11:12].strip() not in chain:\n",
    "    #         continue\n",
    "    #     sequence += ''.join(getSequence(line[19:].split()))\n",
    "    \n",
    "    CA_coords, C_coords, O_coords, N_coords = [], [], [], []\n",
    "    \n",
    "    # chain_id = []\n",
    "    for idx, line in lines['ATOM  ']:\n",
    "        if line[21:22].strip() not in chain:\n",
    "            continue\n",
    "        if line[13:16].strip() == 'CA':\n",
    "            CA_coord = [float(line[30:38]), float(line[38:46]), float(line[46:54])]\n",
    "            CA_coords.append(CA_coord)\n",
    "            sequence += ''.join(getSequence([line[17:20]]))\n",
    "        elif line[13:16].strip() == 'C':\n",
    "            C_coord = [float(line[30:38]), float(line[38:46]), float(line[46:54])]\n",
    "            C_coords.append(C_coord)\n",
    "        elif line[13:16].strip() == 'O':\n",
    "            O_coord = [float(line[30:38]), float(line[38:46]), float(line[46:54])]\n",
    "            O_coords.append(O_coord)\n",
    "        elif line[13:16].strip() == 'N':\n",
    "            N_coord = [float(line[30:38]), float(line[38:46]), float(line[46:54])]\n",
    "            N_coords.append(N_coord)\n",
    "    \n",
    "\n",
    "\n",
    "    return {'title': title,\n",
    "            'seq': sequence,\n",
    "            'CA': np.array(CA_coords),\n",
    "            'C': np.array(C_coords),\n",
    "            'O': np.array(O_coords),\n",
    "            'N': np.array(N_coords),\n",
    "            'score' : 100.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parsePDB('/gaozhangyang/experiments/ProDesign/example/1o91.pdb1.gz', ['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6361, device='cuda:0')\n",
      "MMPAFTACLTTGYPPVGEPVKFDKILYNGRATYDPETGIWTCVVPGTYYFAWVVHCYGGDVLIALYKNDTPMMWVYLEYVDGKLDQASGSAVLRLEPGDEVYLEIPGESADGLYAGEFVHSLFSGFLLHPTEAPAFTALLTTPYPPVGEPIKFDKLLYNGLNVYDPETGIYTCQVPGIYYFAWTVHCLGGDVLVSLYKNDEPMMWTYMEHVEGRLSQASGDAVLELKPGDKVYLEQPTKLANGLAAGDDDHSYFSGFLLHPTEEPAFTALLTVGYPPVGEPIKFDKLLYNGRDVYDPETGIWTCKVPGIYYFAFVVHTKGNDVLVQLYKNDTPMMRVYLEHIDGKLSQASGSGVLRLEKGDKVYIQQPYESANGLAAGARIHSWLSGFLLHPL\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from API.dataloader_gtrans import featurize_GTrans\n",
    "alphabet='ACDEFGHIKLMNPQRSTVWY'\n",
    "batch = featurize_GTrans([data])\n",
    "from methods.utils import cuda\n",
    "X, S, score, mask, lengths = cuda(batch, device = exp.device)\n",
    "X, S, score, h_V, h_E, E_idx, batch_id, mask_bw, mask_fw, decoding_order = exp.method.model._get_features(S, score, X=X, mask=mask)\n",
    "log_probs, logits = exp.method.model(h_V, h_E, E_idx, batch_id, return_logit = True)\n",
    "\n",
    "temperature = 0.1\n",
    "probs = F.softmax(logits/temperature, dim=-1)\n",
    "S_pred = torch.multinomial(probs, 1).view(-1)\n",
    "\n",
    "recovery = torch.mean((S==S_pred).float())\n",
    "S_design = ''.join([alphabet[i] for i in S_pred])\n",
    "\n",
    "print(recovery)\n",
    "print(S_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_true = data['seq']\n",
    "ProteinMPNN = \"EVEAFTALLTTPHPPVGEPIKFNKLVYNGRNVYDPATGIFTVKTPGVYFFTFVLYVYGADLHAELMKNDTPVIKVYLQTVNGKINQVSGAAVLELEEGDKVYVKIPSASANGLWASADAHSYFSGYLLTEKEVEAFTALLTTPHPPVGEPIKFNKLVYNGRNVYDPATGIFTVKTPGVYFFTFVLYVYGADLHAELMKNDTPVIKVYLQTVNGKINQVSGAAVLELEEGDKVYVKIPSASANGLWASADAHSYFSGYLLTEKEVEAFTALLTTPHPPVGEPIKFNKLVYNGRNVYDPATGIFTVKTPGVYFFTFVLYVYGADLHAELMKNDTPVIKVYLQTVNGKINQVSGAAVLELEEGDKVYVKIPSASANGLWASADAHSYFSGYLLTEK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EVEAFTALLTTPHPPVGEPIKFNKLVYNGRNVYDPATGIFTVKTPGVYFFTFVLYVYGADLHAELMKNDTPVIKVYLQTVNGKINQVSGAAVLELEEGDKVYVKIPSASANGLWASADAHSYFSGYLLTEK/EVEAFTALLTTPHPPVGEPIKFNKLVYNGRNVYDPATGIFTVKTPGVYFFTFVLYVYGADLHAELMKNDTPVIKVYLQTVNGKINQVSGAAVLELEEGDKVYVKIPSASANGLWASADAHSYFSGYLLTEK/EVEAFTALLTTPHPPVGEPIKFNKLVYNGRNVYDPATGIFTVKTPGVYFFTFVLYVYGADLHAELMKNDTPVIKVYLQTVNGKINQVSGAAVLELEEGDKVYVKIPSASANGLWASADAHSYFSGYLLTEK'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProteinMPNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('equibind')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43ba559bd9b9425188d86553db18524406fb2a85e37c133054cdad2bbfee5c31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
